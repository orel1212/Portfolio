# Question-answering system based on Orignal Transformer with BytePair GPT2 tokenizer

## Dataset
A corpus that contains a large metadata-rich collection of fictional conversations extracted from raw movie scripts <br>
<a> https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html </a>

## Models
Transformer - original
<a> https://proceedings.neurips.cc/paper/7181-attention-is-all-you-need </a>
<br>
Bytepair GPT2 Tokenizer
<a> https://huggingface.co/docs/transformers/model_doc/gpt2 </a>

### Pytorch

## Files
### question_answering_train.ipynb
running notebook of the code of the train
### question_answering_test.ipynb
running notebook of the code of the test
### transformer.py
full implementation of the transformer with GPT2 Byte-pair tokenizer

## Example
![alt tag](https://github.com/orel1212/MyWorks/blob/main/Deep%20Learning/Transformers/NLP_Sequence_modeling_Original_Transformer/example.png)

